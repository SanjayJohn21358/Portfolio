{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "\n",
    "def soup_maker(url):\n",
    "    '''\n",
    "    Returns a beautiful soup object of the webpage when the webpage URL is passed. The data is scraped\n",
    "    from the beautiful soup object by the rest of the functions\n",
    "    '''\n",
    "    assert isinstance(url,str)\n",
    "    r = requests.get(url)\n",
    "    markup = r.content\n",
    "    soup = bs(markup, 'lxml')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def dwelling_all_details(url,d):\n",
    "    '''\n",
    "    Takes url of a dwelling as the input. Returns all the dwelling details\n",
    "    '''\n",
    "    \n",
    "    assert isinstance(url,str)\n",
    "    all_details = []\n",
    "    soup = soup_maker(url)\n",
    "    \n",
    "    #this bit gets information that's stored in div, span classes\n",
    "    \n",
    "    dwelling_address = soup.title.string\n",
    "    all_details.append(('Address',dwelling_address.string))\n",
    "    dwelling_price = soup.find('div', {'class': 'price'})\n",
    "    all_details.append(('Price',dwelling_price.string))\n",
    "    dwelling_pricechange = soup.find('span', {'class': 'change_down'})\n",
    "    if dwelling_pricechange != None:\n",
    "        all_details.append(('Price Change',dwelling_pricechange.string))\n",
    "    else:\n",
    "        all_details.append(('Price Change',0))\n",
    "    dwelling_pricechangedate = soup.find('span', {'class': 'price_change_date'})\n",
    "    if dwelling_pricechange != None:\n",
    "        all_details.append(('Days Since Price Change',17853 - (int(dwelling_pricechangedate.string))/86000))\n",
    "    else:\n",
    "        all_details.append(('Days Since Price Change','NA'))\n",
    "    \n",
    "    for k, v in all_details:\n",
    "        d[k].append(v)\n",
    "        \n",
    "    #this bit gets all the other information not found in classes, so in <dt>, <dd> tags\n",
    "        \n",
    "    comp_info = pd.DataFrame()\n",
    "    cleaned_id_text = []\n",
    "    cleaned_id_attrb_text = []\n",
    "    info = soup.find_all(\"div\", {'class':'prop-descrip property_detail_specs'})\n",
    "    for j in range(len(info)):\n",
    "        for i in info[j].find_all('dt'):\n",
    "            cleaned_id_text.append(i.text)\n",
    "        for i in info[j].find_all('dd'):\n",
    "            cleaned_id_attrb_text.append(i.text)\n",
    "    \n",
    "    # this replaces any values that aren't there in the listing with default 0\n",
    "    \n",
    "    attribute_list = ['Status','Dwelling Type','Days on Market','Bedrooms', 'Area', 'MLS(R)#','Half baths','Style', 'Community', 'Living Area','Year Built','Total baths', 'Stories']\n",
    "    comp_info['Id'] = cleaned_id_text\n",
    "    comp_info['Attribute'] = cleaned_id_attrb_text\n",
    "    for i in attribute_list:\n",
    "        if i not in list(comp_info.Id):\n",
    "            df2 = pd.DataFrame([[i,0]], columns=['Id','Attribute'])\n",
    "            comp_info = comp_info.append(df2,ignore_index = True)\n",
    "    comp_info = comp_info[comp_info.Id != 'Price Change']\n",
    "    comp_dict = dict(zip(comp_info.Id, comp_info.Attribute))\n",
    "    \n",
    "    #puts it all together in a dataframe\n",
    "    \n",
    "    for k, v in comp_dict.items():\n",
    "        d[k].append(v)\n",
    "\n",
    "    return(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finds all dwelling details from the main webpage\n",
    "### Stores all the information in a dictionary\n",
    "\n",
    "d = collections.defaultdict(list)\n",
    "for i in range(100):\n",
    "    url = 'https://search.vancitycondoguide.com/search/details/h/'+str(i)\n",
    "    result = dwelling_all_details(url,d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts the dataset into a panda dataframe and writes into a CSV file\n",
    "my_df = pd.DataFrame(d)\n",
    "my_df.to_csv('dwellings1.csv',encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
